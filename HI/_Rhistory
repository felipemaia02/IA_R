install.packages("knite")
install.packages("knitr")
install.packages("rmarkdown")
install.packages("plotly")
getOption("repos")
install.packages("stringr")
install.packages("knitr")
install.packages("rmarkdown")
devtools::install_url("http://cran.r-project.org/src/contrib/rmarkdown0.5.1.tar.gz")
getOption("repos")
install.packages("devtools")
devtools::install_github("rstudio/rmarkdown")
install.packages("base64enc", type="binary")
install.packages("jsonlite", type="binary")
install.packages("jsonlite", type = "binary")
install.packages("jsonlite", type = "binary")
devtools::install_github("rstudio/rmarkdown")
library(rmarkdown)
library(markdown)
detach("package:markdown", unload = TRUE)
getOption("repos")
update.packages()
update.packages()
update.packages()
update.packages()
update.packages("stringr")
update.packages("kintr")
install.packages("rmarkdown")
library(rmarkdown)
detach("package:rmarkdown", unload = TRUE)
update.packages()
setwd("~/Faculdade/IA/Trabalho/Lost")
library(e1071)
library(caret)
library(caTools)
base = read.csv("LostLetter.csv")
View(base)
base$X = NULL
View(base)
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
base$Address = NULL
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
#pre-processamento
classificador = naiveBayes(x = base_treinamento[-1], y = base_treinamento$Location)
previsoes = predict(classificador, newdata = base_teste[-1])
matriz_confusao = table(base_teste[, 1], previsoes)
confusionMatrix(matriz_confusao)
library(e1071)
library(caret)
library(caTools)
base = read.csv("LostLetter.csv")
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
base$Location = as.factor(base$Location)
classificador = naiveBayes(x = base_treinamento[-2], y = base_treinamento$Location)
previsoes = predict(classificador, newdata = base_teste[-2])
matriz_confusao = table(base_teste[, 2], previsoes)
confusionMatrix(matriz_confusao)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE
classificador = naiveBayes(x = base_treinamento[-2], y = base_treinamento$Location)
previsoes = predict(classificador, newdata = base_teste[-2])
matriz_confusao = table(base_teste[, 2], previsoes)
confusionMatrix(matriz_confusao)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
#sem pre-processamento
classificador = naiveBayes(x = base_treinamento[-2], y = base_treinamento$Location)
previsoes = predict(classificador, newdata = base_teste[-2])
matriz_confusao = table(base_teste[, 2], previsoes)
confusionMatrix(matriz_confusao)
library(caTools)
library(rpart)
library(rpart.plot)
library(lattice)
library(caret)
library(e1071)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = rpart(formula = Location ~., data = base_treinamento)
previsoes = predict(classificador, newdata = base_teste[-1], type = 'class')
matriz_confusao = table(base_teste[, 1], previsoes)
print(classificador)
plot(classificador)
rpart.plot(classificador)
confusionMatrix(matriz_confusao)
library(caTools)
library(rpart)
library(rpart.plot)
library(lattice)
library(caret)
library(e1071)
base = read.csv("LostLetter.csv")
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = rpart(formula = Location ~., data = base_treinamento)
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
plot(classificador)
rpart.plot(classificador)
confusionMatrix(matriz_confusao)
library(caTools)
library(randomForest)
library(caret)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
#Com pre-processamento
c = rep(0,30)
for(i in 1:30){
classificador = randomForest(x = base_treinamento[-1], y = base_treinamento$Location, ntree = i)
previsoes = predict(classificador, newdata = base_teste[-1], type = 'class')
matriz_confusao = table(base_teste[, 1], previsoes)
print(matriz_confusao)
cm = confusionMatrix(matriz_confusao)
print(confusionMatrix(matriz_confusao))
c[i] = cm$overall['Accuracy']
}
plot(c, type="l")
library(caTools)
library(randomForest)
library(caret)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
#sem pré-processamento
c = rep(0,30)
for(i in 1:30){
classificador = randomForest(x = base_treinamento[-2], y = base_treinamento$Location, ntree = i)
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(matriz_confusao)
cm = confusionMatrix(matriz_confusao)
print(confusionMatrix(matriz_confusao))
c[i] = cm$overall['Accuracy']
}
plot(c, type="l")
library(caTools)
library(randomForest)
library(caret)
base = read.csv("LostLetter.csv")
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
base$Location = as.factor(base$Location)
#sem pré-processamento
c = rep(0,30)
for(i in 1:30){
classificador = randomForest(x = base_treinamento[-2], y = base_treinamento$Location, ntree = i)
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(matriz_confusao)
cm = confusionMatrix(matriz_confusao)
print(confusionMatrix(matriz_confusao))
c[i] = cm$overall['Accuracy']
}
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
#sem pré-processamento
c = rep(0,30)
for(i in 1:30){
classificador = randomForest(x = base_treinamento[-2], y = base_treinamento$Location, ntree = i)
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(matriz_confusao)
cm = confusionMatrix(matriz_confusao)
print(confusionMatrix(matriz_confusao))
c[i] = cm$overall['Accuracy']
}
plot(c, type="l")
library(caTools)
library(h2o)
library(caret)
h2o.init(nthreads = -1)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = h2o.deeplearning(y = 'Location',
training_frame = as.h2o(base_treinamento),
activation = 'Rectifier',
hidden = c(80, 160),
epochs = 1000)
#Pre-processamento
previsoes = h2o.predict(classificador, newdata = as.h2o(base_teste[-1]))
previsoes = (previsoes > 0.5)
previsoes = as.vector(previsoes)
library(caTools)
library(h2o)
library(caret)
h2o.init(nthreads = -1)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
base$Location = as.numeric(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = h2o.deeplearning(y = 'Location',
training_frame = as.h2o(base_treinamento),
activation = 'Rectifier',
hidden = c(80, 160),
epochs = 1000)
#Pre-processamento
previsoes = h2o.predict(classificador, newdata = as.h2o(base_teste[-1]))
previsoes = as.vector(previsoes)
previsoes = (previsoes > 0.5)
previsoes = as.vector(previsoes)
predicted = previsoes
#Pre-processamento
reference = base_teste[, 1]
u = union(reference, predicted)
matriz_confusao = table(c(predicted, u), c(reference, u))
confusionMatrix(matriz_confusao)
library(caTools)
library(h2o)
library(caret)
h2o.init(nthreads = -1)
base = read.csv("LostLetter.csv")
base$X = NULL
base$Address = NULL
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
#escalonamento
base[,2:7]= scale(base[, 2:7])
base$Location = as.factor(base$Location)
base$Location = as.numeric(base$Location)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = h2o.deeplearning(y = 'Location',
training_frame = as.h2o(base_treinamento),
activation = 'Rectifier',
hidden = c(80, 160),
epochs = 1000)
library(caTools)
library(h2o)
library(caret)
h2o.init(nthreads = -1)
base = read.csv("LostLetter.csv")
#inconsistentes
base$Location = factor(base$Location, levels = unique(base$Location), labels = c(1,2,3))
base$Location = as.factor(base$Location)
base$Location = as.numeric(base$Location)
classificador = h2o.deeplearning(y = 'Location',
training_frame = as.h2o(base_treinamento),
activation = 'Rectifier',
hidden = c(80, 160),
epochs = 1000)
set.seed(1)
divisao = sample.split(base$Location, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
a
classificador = h2o.deeplearning(y = 'Location',
training_frame = as.h2o(base_treinamento),
activation = 'Rectifier',
hidden = c(80, 160),
epochs = 1000)
#sem pre-processamento
previsoes = h2o.predict(classificador, newdata = as.h2o(base_teste[-2]))
previsoes = (previsoes > 0.5)
previsoes = as.vector(previsoes)
predicted = previsoes
#sem pre-processamento
reference = base_teste[, 2]
u = union(reference, predicted)
matriz_confusao = table(c(predicted, u), c(reference, u))
confusionMatrix(matriz_confusao)
setwd("~/Faculdade/IA/Trabalho/HI")
library(e1071)
library(caret)
library(caTools)
#Esse dataset nÃ£o apresenta dados faltantes
data = read.csv("HI.csv")
#Tirando valores, apenas utilizar se for fazer prÃ©-processamento
data$X = NULL
data$hhi = NULL
data$whi = NULL
data$hhi2 = NULL
data$wght = NULL
data$region = NULL
data$education = NULL
summary(data)
#inconsistentes
data$whrswk = ifelse(data$whrswk <= 0, mean(data$whrswk), data$whrswk)
data$experience = ifelse(data$whrswk <= 0, mean(data$whrswk), data$whrswk)
#escalonamento
data[,1] = scale(data[,1])
data[,4:7] = scale(data[,4:7])
data$race = factor(data$race, levels = unique(data$race), labels = c(1,2,3))
data$hispanic = factor(data$hispanic, levels = unique(data$hispanic), labels = c(1,2))
#Fazendo as divisÃµes das bases
set.seed(1)
divisao = sample.split(data$race, SplitRatio = 0.75)
base_treinamento = subset(data, divisao == TRUE)
base_teste = subset(data, divisao == FALSE)
#Sem prÃ©-processamento
#classificador = naiveBayes(x = base_treinamento[-7], y = base_treinamento$race)
#previsoes = predict(classificador, newdata = base_teste[-7])
#matriz_confusao = table(base_teste[, 7], previsoes)
#Com prÃ©-processamento
classificador = naiveBayes(x = base_treinamento[-2], y = base_treinamento$race)
previsoes = predict(classificador, newdata = base_teste[-2])
matriz_confusao = table(base_teste[, 2], previsoes)
#Gerando a matriz
confusionMatrix(matriz_confusao)
library(e1071)
library(caret)
library(caTools)
#Esse dataset nÃ£o apresenta dados faltantes
data = read.csv("HI.csv")
#Tirando valores, apenas utilizar se for fazer prÃ©-processamento
data$X = NULL
data$hhi = NULL
data$whi = NULL
data$hhi2 = NULL
data$wght = NULL
data$region = NULL
data$education = NULL
summary(data)
#inconsistentes
data$whrswk = ifelse(data$whrswk <= 0, mean(data$whrswk), data$whrswk)
data$experience = ifelse(data$whrswk <= 0, mean(data$whrswk), data$whrswk)
set.seed(1)
divisao = sample.split(data$race, SplitRatio = 0.75)
base_treinamento = subset(data, divisao == TRUE)
base_teste = subset(data, divisao == FALSE)
classificador = naiveBayes(x = base_treinamento[-2], y = base_treinamento$race)
previsoes = predict(classificador, newdata = base_teste[-2])
matriz_confusao = table(base_teste[, 2], previsoes)
#Gerando a matriz
confusionMatrix(matriz_confusao)
library(e1071)
library(caret)
library(caTools)
#Esse dataset nÃ£o apresenta dados faltantes
data = read.csv("HI.csv")
classificador = naiveBayes(x = base_treinamento[-7], y = base_treinamento$race)
previsoes = predict(classificador, newdata = base_teste[-7])
matriz_confusao = table(base_teste[, 7], previsoes)
#Fazendo as divisÃµes das bases
set.seed(1)
divisao = sample.split(data$race, SplitRatio = 0.75)
base_treinamento = subset(data, divisao == TRUE)
base_teste = subset(data, divisao == FALSE)
classificador = naiveBayes(x = base_treinamento[-7], y = base_treinamento$race)
previsoes = predict(classificador, newdata = base_teste[-7])
matriz_confusao = table(base_teste[, 7], previsoes)
#Gerando a matriz
confusionMatrix(matriz_confusao)
library(caTools)
library(rpart)
library(rpart.plot)
library(lattice)
library(caret)
library(e1071)
#pegando a base de dados
base = read.csv("HI.csv")
#Tirando valores, apenas utilizar se for fazer prÃ©-processamento
base$X = NULL
base$hhi = NULL
base$whi = NULL
base$hhi2 = NULL
base$wght = NULL
base$education = NULL
base$region = NULL
base[,1] = scale(base[,1])
base[,4:7] = scale(base[,4:7])
base$race = factor(base$race, levels = unique(base$race), labels = c(1,2,3))
base$hispanic = factor(base$hispanic, levels = unique(base$hispanic), labels = c(1,2))
#Fazendo as divisÃµes das bases
set.seed(1)
divisao = sample.split(base$race, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 6, minbucket = 6, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
#Com escalonamento/inconsistentes/pre-processamento
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 6, minbucket = 6, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
plot(classificador)
rpart.plot(classificador)
#Sem escalonamento/inconsistentes
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 21, minbucket = 9, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
plot(classificador)
rpart.plot(classificador)
#Sem escalonamento/inconsistentes
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 25, minbucket = 25, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
plot(classificador)
#Sem escalonamento/inconsistentes
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 20, minbucket = 20, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
print(classificador)
plot(classificador)
rpart.plot(classificador)
library(caTools)
library(rpart)
library(rpart.plot)
library(lattice)
library(caret)
library(e1071)
#pegando a base de dados
base = read.csv("HI.csv")
#Tirando valores, apenas utilizar se for fazer prÃ©-processamento
base$X = NULL
base$hhi = NULL
base$whi = NULL
base$hhi2 = NULL
base$wght = NULL
base$education = NULL
base$region = NULL
#inconsistentes
base$whrswk = ifelse(base$whrswk <= 0, mean(base$whrswk), base$whrswk)
base$experience = ifelse(base$whrswk <= 0, mean(base$whrswk), base$whrswk)
#escalonamento
base[,1] = scale(base[,1])
base[,4:7] = scale(base[,4:7])
base$race = factor(base$race, levels = unique(base$race), labels = c(1,2,3))
base$hispanic = factor(base$hispanic, levels = unique(base$hispanic), labels = c(1,2))
#Fazendo as divisÃµes das bases
set.seed(1)
divisao = sample.split(base$race, SplitRatio = 0.75)
base_treinamento = subset(base, divisao == TRUE)
base_teste = subset(base, divisao == FALSE)
summary(base)
#Sem pre-processamento
#classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 31, minbucket = 31, cp=0))
#previsoes = predict(classificador, newdata = base_teste[-7])
#previsoes = predict(classificador, newdata = base_teste[-7], type = 'class')
#matriz_confusao = table(base_teste[, 7], previsoes)
#Com escalonamento/inconsistentes/pre-processamento
classificador = rpart(formula = race ~., data = base_treinamento,control =rpart.control(minsplit = 6, minbucket = 6, cp=0))
previsoes = predict(classificador, newdata = base_teste[-2])
previsoes = predict(classificador, newdata = base_teste[-2], type = 'class')
matriz_confusao = table(base_teste[, 2], previsoes)
confusionMatrix(matriz_confusao)
